# Install if not already: pip install nltk
 
import nltk
from nltk.wsd import lesk
from nltk.corpus import wordnet as wn
from nltk.tokenize import word_tokenize
 
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')
 
# Example sentences with ambiguous words
sentences = [
    "He went to the bank to deposit some money.",
    "The fisherman sat on the bank of the river.",
    "They need to book a room for the conference.",
    "She read a fascinating book about AI."
]
 
# Target ambiguous words
target_words = ['bank', 'bank', 'book', 'book']
 
# Apply Lesk algorithm to disambiguate word senses
print("ğŸ§  Word Sense Disambiguation (Lesk Algorithm):\n")
for sentence, word in zip(sentences, target_words):
    context = word_tokenize(sentence)
    sense = lesk(context, word)
    print(f"ğŸ“Œ Sentence: {sentence}")
    if sense:
        print(f"ğŸ” Disambiguated Sense: {sense.name()} â€“ {sense.definition()}\n")
    else:
        print("âš ï¸ Could not disambiguate the word.\n")